{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract citation rate by age of publication from dblp data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, some setup. We need to pass the right java home here because the spark version we have does not work with newer JDK versions (Java 8 works, though). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib64/jvm/jre-1.8.0-openjdk\"\n",
    "os.environ[\"SPARK_HOME\"] = \"/home/sven/spark/spark-2.3.2-bin-hadoop2.7\"\n",
    "os.environ[\"PYTHONHASHSEED\"] = \"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Citation data came from [Arnet Miner](https://aminer.org/citation) in JSON format; we used the dataset V10, but the other versions should also work. The files are large-ish, so we recommend reading and processing them locally rather than to using a colab notebook and uploading them. Change the line below depending on where you read the data from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "citationData = spark.read.json('./dblp-ref-*.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll take (publicationId, list of referenceIds, publication year) for all publications that have at least one reference. Then run a map-reduce combination to map this to\n",
    "(referenceId + \".\" + year) -> counter.\n",
    "Then run another map to split the reference ids and the years apart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dd = citationData.select(\"id\", \"references\", \"year\").filter(\"references is not NULL\").rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docsplit = dd.flatMap(lambda row: [('{}.{}'.format(ref, row[2]), 1) for ref in row[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reducestep = docsplit.reduceByKey(lambda c, d : c + d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idYearCount = reducestep.map(lambda row: (row[0][:-5], int(row[0][-4:]), row[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make pair rdds so we can join the publication date and the citation dates.\n",
    "idYear = idYearCount.map(lambda row: (row[0], row[1]))\n",
    "ddpairs = dd.map(lambda row: (row[0], row[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idYearAge = idYear.join(ddpairs).filter(lambda row: (row[1][0] - row[1][1] >= -2)).map(lambda row: ('{}.{}'.format(row[0], row[1][0]), (row[1][0] - row[1][1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do a double check: there are some papers with citations 80+ years post-publication, look them up to make sure this isn't a bug or a fault in the data. Looks to be fine though -- these are all papers that really were published\n",
    "in the 1930s (looks like they're the oldest papers that DBLP has records for?)\n",
    "It may be useful to exclude very old papers from stats, since citation behaviour may have changed over time. But for now let's leave them in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for row in idYearAge.sortBy(lambda x : x[1], ascending=False).take(10):\n",
    "  d = citationData.filter(\"id == \\'{}\\'\".format(row[0][:-5])).drop('abstract').collect()\n",
    "  print(\"{}\".format(d[0]))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# join with reducestep to get ref.yearCited -> (age, citationCount)\n",
    "# take the yearCited out of ref again and reduce.\n",
    "# That should give us\n",
    "# refId -> [(age, citationCountAtAge)]\n",
    "citationCountByAgeAndId = idYearAge.join(reducestep).map(lambda row: (row[0][:-5], [(row[1][0], row[1][1])])).reduceByKey(lambda c, d: c + d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not necessary to run this, but gives a quick overview what the data looks like\n",
    "citationCountByAgeAndId.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform this data so it's just arrays of citation counts where array[i] = citation count at age i.\n",
    "# Use mapValues and make sure to insert zeroes for missing citation counts.\n",
    "# This is for plotting the citation counts over time of selected publications. We do this instead of using list(zip(*pairs))\n",
    "# because we want 0 values to be inserted for missing years. We're not padding the array with 0 citation counts though,\n",
    "# so if the publication has no citations after age x (either because it was forgotten or because it was published\n",
    "# less than x years ago), it will not contribute to stats for age x+.\n",
    "\n",
    "def pairsToArray(pairs):\n",
    "    d = dict(pairs)\n",
    "    return [d[x] if (x in d) else 0 for x in range(max(d.keys()) + 1)]\n",
    "\n",
    "sample = citationCountByAgeAndId.mapValues(pairsToArray).take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#again, not necessary to run this, just gives a glimpse at the data\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next, avg and max citation counts by year over all publications. Below is a dataframe version.\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType\n",
    "\n",
    "schema = StructType([StructField('Age', IntegerType(), False),\n",
    "                     StructField('CitCount', IntegerType(), True)])\n",
    "\n",
    "# This will fail to count 0 values\n",
    "# cc = citationCountByAgeAndId.flatMap(lambda row : [(x[0], x[1]) for x in row[1]]).toDF(schema)\n",
    "\n",
    "# Instead, use pairsToArray to get lists of citation counts (list[i] == citation count at age i)\n",
    "citCountArrays = citationCountByAgeAndId.mapValues(pairsToArray)\n",
    "# transform these back to pairs, dropping the publication id. now we have lots of pairs\n",
    "# (age, citationCount). Could have used aggregateByKey or aggregate here instead and avoided\n",
    "# the transformation to a dataframe.\n",
    "ccList = citCountArrays.flatMap(lambda row: [(idx, v) for idx, v in enumerate(row[1])])\n",
    "cc = ccList.toDF(schema)\n",
    "\n",
    "from pyspark.sql import functions\n",
    "\n",
    "averages = cc.groupBy('Age').agg(functions.avg('CitCount').alias('Avg')).orderBy('Age').collect()\n",
    "maxcount = cc.groupBy('Age').agg(functions.max('CitCount').alias('Max')).orderBy('Age').collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "years = []\n",
    "citcounts = []\n",
    "maxcounts = []\n",
    "for av in averages:\n",
    "    years.append(av.Age)\n",
    "    citcounts.append(av.Avg)\n",
    "\n",
    "for mx in maxcount:\n",
    "    maxcounts.append(mx.Max)\n",
    "    \n",
    "avgFig = plt.figure()\n",
    "ax1 = plt.axes()\n",
    "\n",
    "ax1.set_xlabel('years since publication')\n",
    "ax1.set_ylabel('avg citation count', color='b')\n",
    "ax1.plot(years, citcounts, 'b')\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax2.set_ylabel('max citation count', color='r')\n",
    "ax2.plot(years, maxcounts, 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try the same aggregation on the rdd, it should be faster.\n",
    "# citCountArrays is publication id -> [list of citation counts] where the ith entry in the list is the\n",
    "# number of times the publication was cited when it was i years 'old' (i.e., i years after it was published).\n",
    "citCountArrays = citationCountByAgeAndId.mapValues(pairsToArray)\n",
    "\n",
    "# the max len of these is 81. Could extract that number here just to be safe, but we'll just use 100\n",
    "# as the max age for now. Use rdd.aggregate where the tuples are pairs of arrays. Each array has 100\n",
    "# entries, one for each year of publication age. The first array accumulates the sums of citation counts,\n",
    "# the second counts how many times we've seen a citation count for a given year.\n",
    "startingTuple = ([0] * 100, [0] * 100)\n",
    "\n",
    "def seqOp(acc, newItem):\n",
    "    for idx, value in enumerate(newItem[1]):\n",
    "        acc[0][idx] += value\n",
    "        acc[1][idx] += 1\n",
    "    return acc\n",
    "\n",
    "def combOp(acc1, acc2):\n",
    "    # acc1 will contain two tuples each with a length of 100. So should acc2.\n",
    "    return ([x1 + x2 for x1,x2 in zip(acc1[0], acc2[0])], [y1 + y2 for y1,y2 in zip(acc1[1], acc2[1])])\n",
    "\n",
    "sumsAndCounts = citCountArrays.aggregate(startingTuple, seqOp, combOp)\n",
    "averageByAggregate = [(x / y if y > 0 else 0) for x,y in zip(sumsAndCounts[0], sumsAndCounts[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avgFig = plt.figure()\n",
    "ax1 = plt.axes()\n",
    "\n",
    "years = range(100)\n",
    "ax1.set_xlabel('years since publication')\n",
    "ax1.set_ylabel('avg citation count', color='b')\n",
    "ax1.plot(years, averageByAggregate, 'b')\n",
    "\n",
    "# Note the red plot is different data from the graph above where I used dataframes.\n",
    "# The red line here is a log-scale graph of the number of publications that I had\n",
    "# citation data for for a given age. It might go some way towards explaining how much\n",
    "# smoother the blue line is for 'younger' citation ages.\n",
    "ax2 = ax1.twinx()\n",
    "ax2.set_ylabel('number of publications cited at this age', color='r')\n",
    "ax2.semilogy(years, sumsAndCounts[1], 'r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Average citation counts get high and spiky at about 70 years post-publication, perhaps because DBLP does not track many older papers, and those that they do track tend to be classics (papers by Post, Church, Turing, Kleene). These papers were published in the 1930's, so the rise in citation rates started in the early 2000's which makes sense given overall increases in publication rates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Papers sorted into quantiles by their overall citation count. For simplicity, we'll use the n_citation field even though it does not line up perfectly with references that are actually in DBLP.\n",
    "Quantiles of n_citation values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_citation_quantiles = citationData.approxQuantile(\"n_citation\", [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9], 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_citation_quantiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can this be correct? Count below shows we have so many pubs at 0 citations that they get two buckets. Maybe same\n",
    "# situation at 50 (is that a DBLP artifact? looks suspiciously round). The numbers are plausible -- about 300k\n",
    "# publications per decile adds up to the ca. 3 million publications in the dataset. This does mean we should adapt\n",
    "# the effective quantile boundary list though.\n",
    "pubsWithNoCitations = citationData.filter(\"n_citation = 0\").count()\n",
    "pubsWithFewCitations = citationData.filter(\"n_citation < 3\").filter(\"n_citation > 0\").count()\n",
    "pubsWith50Citations = citationData.filter(\"n_citation = 50\").count()\n",
    "pubsWithManyCitation = citationData.filter(\"n_citation > 50\").count()\n",
    "\n",
    "print(\"no citations: {}, fewer than 3: {}, exactly 50: {}, more than 50: {}\".format(\\\n",
    "    pubsWithNoCitations, pubsWithFewCitations, pubsWith50Citations, pubsWithManyCitation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now sort paper ids into buckets. Use an adapted quantile boundary list. Note these are not quantiles --\n",
    "# the first bucket (0 citations) contains about 700k publications, the 50-51 bucket about 850k, so they're\n",
    "# each roughly the size of two to three deciles.\n",
    "buckets = [0.0, 2.0, 4.0, 11.0, 33.0, 50.0, 51.0]\n",
    "def bucketForCitCount(citCount):\n",
    "    for idx, qq in enumerate(buckets):\n",
    "        if citCount < qq:\n",
    "            return idx\n",
    "    return len(n_citation_quantiles)\n",
    "\n",
    "pubIdWithBucket = citationData.select(\"id\", \"n_citation\").rdd.mapValues(lambda x : bucketForCitCount(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pubIdWithBucket.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "citCountByAgeWithBucket = citCountArrays.join(pubIdWithBucket).coalesce(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "citCountByAgeWithBucket.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we want to group by the bucket, so map and make the buckets the keys, dropping the pub ids.\n",
    "# Then use aggregateByKey with the aggregation settings declared above for the overall averages.\n",
    "citCountByAgeWithBucket.map(lambda row: (row[1][1], row[1][0])).take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "startingTuple = ([0] * 100, [0] * 100)\n",
    "\n",
    "def seqOp(acc, newItem):\n",
    "    for idx, value in enumerate(newItem):\n",
    "        acc[0][idx] += value\n",
    "        acc[1][idx] += 1\n",
    "    return acc\n",
    "\n",
    "def combOp(acc1, acc2):\n",
    "    # acc1 will contain two tuples each with a length of 100. So should acc2.\n",
    "    return ([x1 + x2 for x1,x2 in zip(acc1[0], acc2[0])], [y1 + y2 for y1,y2 in zip(acc1[1], acc2[1])])\n",
    "\n",
    "sumsAndCounts = citCountByAgeWithBucket.map(lambda row: (row[1][1], row[1][0])).aggregateByKey(startingTuple, seqOp, combOp)\n",
    "# sumsAndCounts contains tuples of the form (<bucket>, ([list of sums of citation counts], [list of citation counts]))\n",
    "averageByAggregate = sumsAndCounts.mapValues(lambda row: ([(x / y if y > 0 else 0) for x,y in zip(row[0], row[1])]))\n",
    "\n",
    "averagesByBucket = averageByAggregate.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = plt.axes()\n",
    "\n",
    "colours = ['b', 'r', 'g', 'c', 'm', 'y', 'k', 'w', 'rosybrown']\n",
    "\n",
    "for idx, s in enumerate(averagesByBucket):\n",
    "    x = range(len(s[1]))\n",
    "    ax.plot(x, s[1], color=colours[idx], label=\"Citation Counts for Bucket {}\".format(idx))\n",
    "    ax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.05), shadow=True, ncol=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The citation count development really isn't significantly different per bucket except for (maybe) the bucket with the most citations (over 50 overall)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import array_contains, lower, col\n",
    "\n",
    "# Proceedings of VLDB conference changed their name at some point\n",
    "vldbPapers1 = citationData.filter(\"lower(venue) like '%very large data bases%'\")\n",
    "vldbPapers2 = citationData.filter(\"lower(venue) like '%vldb endowment%'\")\n",
    "vldbPapers = vldbPapers1.union(vldbPapers2).select(\"authors\", \"id\", \"title\", \"venue\", \"year\").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vldbids = vldbPapers1.union(vldbPapers2).select(\"id\").collect()\n",
    "vldbarray = [str(row.id) for row in vldbids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at winners of the VLDB 10-year best paper award.\n",
    "# Obtained here: http://www.vldb.org/archives/10year.html\n",
    "vldb10YearBest = [\n",
    "    # Nilesh N. Dalvi, Dan Suciu: Efficient query evaluation on probabilistic databases (2004)\n",
    "    'df3ea837-9b41-44e4-a049-0ad9d5b65853',\n",
    "    # Manku, Motwani: Approximate frequency counts over data streams (2012)\n",
    "    # Mislaid at wrong publication date\n",
    "    'ce60ea5e-1cdb-415a-9c56-231db02111c4',\n",
    "    # Jayant Madhavan,Philip A. Bernstein,Erhard Rahm: Generic Schema Matching with Cupid (2001)\n",
    "    '91556b20-c53e-4687-82e2-7c3c1e893f0b',\n",
    "    # Bettina Kemme,Gustavo Alonso: Database replication: a tale of research across communities (2010)\n",
    "    # Note DBLP has this misclassified under the later pub date\n",
    "    '51614021-0039-48a3-b62b-13dd593a87be',\n",
    "    # Boncz, Manegold, Kersten: Database Architecture Optimized for the New Bottleneck: Memory Access. (1999)\n",
    "    '1c14e793-fc96-465e-949a-b109b6c4a762',\n",
    "    # also published in IEEE as 'ee631708-8eb7-48ef-9e93-2cc0a3c145c0'\n",
    "    \n",
    "    # Weber, Schek, Blott: A Quantitative Analysis and Performance Study for Similarity-Search Methods in High-Dimensional Spaces (1998)\n",
    "    '7a5b23b4-b171-4c19-8925-167583868f93'\n",
    "    # Chaudhuri, Narasayva: An Efficient Cost-Driven Index Selection Tool for Microsoft SQL Server (1997)\n",
    "    '720f4495-31e3-4f14-b748-e30188147bcc',\n",
    "    # Levy, Rajaraman, Ordille: Querying Heterogeneous Information Sources Using Source Descriptions (1996)\n",
    "    'd5b735f0-712a-4000-9176-54d487fc7bf9',\n",
    "    # Konopnicki, Shmueli: W3QS: A Query System for the World-Wide Web (1995)\n",
    "    '6b95f187-1b14-46d4-965f-50771f2453fb',\n",
    "  # Bancilhon, Kim and Korth: A Model of CAD Transactions (1985)\n",
    "  'ec8ed5f7-51f6-47e3-8b04-97e5fe0122b7',\n",
    "  # Carey, DeWitt, Richardson, Shekita: Object and File Management in the EXODUS extensible database system (1986)\n",
    "  '38d1e121-9085-4ba7-a410-f4c5092bace7',\n",
    "   # Sellis, Roussopoulos, Faloutsos: The R+-Tree: A Dynamic Index for Multi-Dimensional Objects (1987)\n",
    "  '783e5a24-8505-4817-9566-36b1a478a6be',\n",
    "  # Bitton, Gray: Disk Shadowing (1988)\n",
    "  'caedea34-0d62-4fde-81e0-bf28bb00172c',\n",
    "  # Rothermel, Mohan: ARIES/NT: a recovery method based on write-ahead logging for nested transactions (1989)\n",
    "    '923a01ef-c302-41cc-a30e-49709ef84a89',\n",
    "  # Ceri, Widom: Deriving Production Rules for Constraint Maintainance (1990)\n",
    "    '19ac2523-01b1-49d5-94db-f5b824264366',\n",
    "  # Dayal, Hsu, Ladin: A Transactional Model for Long-Running Activities (1991)\n",
    "    'fc3727a8-3618-4202-b416-a6cdb01410a9',\n",
    "  # Monkeberg, Weikum: Performance Evaluation of an Adaptive and Robust Load Control Method for the Avoidance of Data-Contention Thrashing (1992)\n",
    "    '3fba053a-72ab-485b-bf16-227d196db160',\n",
    "    # Imielinski, Badrinath: Querying in Highly Mobile Distributed Environments (1992)\n",
    "    '5a1ded12-77ad-4d92-b5f1-e7d0ce7768c1',\n",
    "  # Ioannidis: Universality of Serial Histograms (1993)\n",
    "  'db115e6b-db3c-4088-afc2-8cc84ee40466',\n",
    "  # Agrawal, Srikant: Fast Algorithms for Mining Association Rules in Large Databases (1994)\n",
    "    '34b7e270-80d7-46d5-a6f1-e50087a8d045',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vldbCitationHistory = citCountArrays.filter(lambda row: row[0] in vldb10YearBest).collect()\n",
    "vldbCitNoCollect = citCountArrays.filter(lambda row: row[0] in vldb10YearBest)\n",
    "allvldbCitationHistory = citCountArrays.filter(lambda row: row[0] in vldbarray).collect()\n",
    "allvldbNoCollect = citCountArrays.filter(lambda row: row[0] in vldbarray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vldbList = allvldbNoCollect.flatMap(lambda row: [(idx, v) for idx, v in enumerate(row[1])])\n",
    "vv = vldbList.toDF(schema)\n",
    "\n",
    "vaverages = vv.groupBy('Age').agg(functions.avg('CitCount').alias('Avg')).orderBy('Age').collect()\n",
    "vmaxcount = vv.groupBy('Age').agg(functions.max('CitCount').alias('Max')).orderBy('Age').collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now compare the 10-year best paper award VLDB papers to the average citation count of all VLDB papers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vaverages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vldbavg = [('vldb average',\n",
    "[0.6082731123847496,\n",
    "3.2832747363134103,\n",
    "4.68223805753497,\n",
    "5.129105969722937,\n",
    "5.318125,\n",
    "5.151855635001702,\n",
    "4.870168855534709,\n",
    "4.553482587064677,\n",
    "4.196270396270396,\n",
    "3.9302446642373763,\n",
    "3.6951147733961154,\n",
    "3.666444296197465,\n",
    "3.3752825923134893,\n",
    "3.2354430379746835,\n",
    "2.901140684410646,\n",
    "2.872707659115426,\n",
    "2.70933014354067,\n",
    "2.537837837837838,\n",
    "2.540372670807453,\n",
    "2.261986301369863,\n",
    "1.9980544747081712,\n",
    "1.8820960698689957,\n",
    "1.9772151898734178,\n",
    "1.237082066869301,\n",
    "1.1263537906137184,\n",
    "1.0991735537190082,\n",
    "1.2376237623762376,\n",
    "1.2241379310344827,\n",
    "1.0785714285714285,\n",
    "1.192,\n",
    "1.0467289719626167,\n",
    "0.8636363636363636,\n",
    "1.196969696969697,\n",
    "1.2,\n",
    "1.6,\n",
    "1.6129032258064515,\n",
    "1.608695652173913,\n",
    "1.375,\n",
    "1.75,\n",
    "1.5555555555555556,\n",
    "1.0,\n",
    "3.0])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = plt.axes()\n",
    "\n",
    "colours = ['b', 'r', 'g', 'c', 'm', 'y', 'k', 'w', 'rosybrown']\n",
    "\n",
    "ax.set_xlabel('years since publication')\n",
    "\n",
    "#for idx, s in enumerate(fivevldb):\n",
    "for idx, s in enumerate(vldbCitationHistory):\n",
    "    x = range(len(s[1]))\n",
    "    if (idx != 0):\n",
    "        ax.plot(x, s[1], color=colours[0])\n",
    "#    ax.plot(x, s[1], color=colours[0], label=\"Citation Counts for id {}\".format(s[0]))\n",
    "    ax.set_ylim(bottom=0, top=100)\n",
    "\n",
    "for idx, s in enumerate(vldbCitationHistory):\n",
    "    x = range(len(s[1]))\n",
    "    if (idx == 0):\n",
    "        ax.plot(x, s[1], color=colours[0], label=\"Citation counts for award winners\")\n",
    "#    ax.plot(x, s[1], color=colours[0], label=\"Citation Counts for id {}\".format(s[0]))   \n",
    "    \n",
    "    \n",
    "for idx, s in enumerate(vldbavg):    \n",
    "    x = range(len(s[1]))\n",
    "    ax.plot(x, s[1], color=colours[1], label=\"Avg citation counts for all VLDB papers\".format(s[0]))\n",
    "    \n",
    "ax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.17), shadow=True, ncol=2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
